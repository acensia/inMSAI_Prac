{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "RANDOM_SEED = 42\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./mnist_data\", train=True, transform=transform, download=True)\n",
    "valid_dataset = datasets.MNIST(root=\"./mnist_data\", train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, class_number):\n",
    "        super(LeNet5, self).__init__()   \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            ## (32, 6, h, w)\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2), # >> feat. map size goes half\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=class_number)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1) \n",
    "        logits = self.classifier(x) # logits for each class\n",
    "        probs = F.softmax(logits, dim=1) #probs for each class\n",
    "        \n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(model, data_loader, device) :\n",
    "    \n",
    "    correct_pred = 0\n",
    "    n = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        for x, y_true in data_loader:\n",
    "            x = x.to(device)\n",
    "            y = y_true.to(device)\n",
    "            \n",
    "            _, y_prob = model(x)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "            \n",
    "            \n",
    "    return correct_pred.float() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_hat, _ = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for x, y_true in valid_loader:\n",
    "        x = x.to(device)\n",
    "        y = y_true.to(device)\n",
    "        \n",
    "        y_hat, _ = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "            \n",
    "            \n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader,epochs,device,pring_every=1):\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "            \n",
    "        if epoch % pring_every == (pring_every - 1) :\n",
    "            train_acc = get_acc(model, train_loader, device=device)\n",
    "            valid_acc = get_acc(model, valid_loader, device=device)\n",
    "            \n",
    "            print(f\"{datetime.now().time().replace(microsecond=0)}--------\"\n",
    "                  f\"Epoch: {epoch + 1}\\t\"\n",
    "                  f\"train loss : {train_loss:.4f}\\t\"\n",
    "                  f\"Valid loss : {valid_loss:.4f}\\t\"\n",
    "                  f\"Train ACC : {100 * train_acc:.2f}\\t\"\n",
    "                  f\"Valid ACC : {100 * valid_acc:.2f}\")\n",
    "            \n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[0;32m      4\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 5\u001b[0m model, optimizer, _ \u001b[39m=\u001b[39m training_loop(model, criterion, optimizer, train_loader, valid_loader, class_number, DEVICE)\n",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(model, criterion, optimizer, train_loader, valid_loader, epochs, device, pring_every)\u001b[0m\n\u001b[0;32m     12\u001b[0m     valid_losses\u001b[39m.\u001b[39mappend(valid_loss)\n\u001b[0;32m     14\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m pring_every \u001b[39m==\u001b[39m (pring_every \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) :\n\u001b[1;32m---> 15\u001b[0m     train_acc \u001b[39m=\u001b[39m get_acc(model, train_loader, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     16\u001b[0m     valid_acc \u001b[39m=\u001b[39m get_acc(model, valid_loader, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mtime()\u001b[39m.\u001b[39mreplace(microsecond\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m--------\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain loss : \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid loss : \u001b[39m\u001b[39m{\u001b[39;00mvalid_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain ACC : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid ACC : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mvalid_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mget_acc\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m         _, y_prob \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     14\u001b[0m         _, predicted_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(y_prob, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mreturn\u001b[39;00m correct_pred\u001b[39m.\u001b[39;49mfloat() \u001b[39m/\u001b[39m n\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = LeNet5(class_number).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader, class_number, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
