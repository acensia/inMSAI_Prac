{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "객체 추적 알고리즘\n",
    "<div style=\"text-align: right\"> 최준혁2 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video_path = './data/slow_traffic_small.mp4'\n",
    "\n",
    "def MeanShift(path):\n",
    "    # init rectangle for mean shift tracking\n",
    "    track_window = None #temp for object loc data\n",
    "    roi_hist = None #temp for histogram\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    cap = cv2.VideoCapture(\"./data/slow_traffic_small.mp4\")\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    # print(ret, frame)\n",
    "\n",
    "\n",
    "    x, y, w, h = cv2.selectROI(\"selectROI\", frame, False, False)\n",
    "\n",
    "    #calculate init histogram of tracked obj\n",
    "    roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "    # cv2.imshow(\"roi test\", roi)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 100])\n",
    "    cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # set init window for tracked obj\n",
    "    track_window = (x, y, w, h)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist, [0, 180], 1)\n",
    "\n",
    "        _, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        x, y, w, h = track_window\n",
    "        print(\"추적 결과 좌표\", x, y, w, h)\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "        cv2.imshow(\"MeanShift Tracking\",frame)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF==ord('q'):\n",
    "            exit()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def Kalman(path):\n",
    "    kalman = cv2.KalmanFilter(4,2)\n",
    "    kalman.measurementMatrix = np.array([[1,0,0,0],\n",
    "                                         [0,1,0,0]], np.float32)\n",
    "    \n",
    "    kalman.transitionMatrix = np.array([[1, 0, 0, 0],\n",
    "                                        [0, 1, 0, 1],\n",
    "                                        [0, 0, 1, 0],\n",
    "                                        [0, 0, 0, 1]], np.float32)\n",
    "    \n",
    "    kalman.processNoiseCov = np.array([[1, 0, 0, 0],\n",
    "                                     [0, 1, 0, 0],\n",
    "                                     [0, 0, 1, 0],\n",
    "                                     [0, 0, 0, 1]], np.float32) * 0.05\n",
    "    \n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    bbox = cv2.selectROI(\"Select Object\", frame, False, False)\n",
    "    kalman.statePre = np.array([[bbox[0]],\n",
    "                                [bbox[1]],\n",
    "                                [0],\n",
    "                                [0]], np.float32)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        kalman.correct(np.array([[np.float32(bbox[0] + bbox[2] / 2)],\n",
    "                                 [np.float32(bbox[1] + bbox[3] / 2)]]))\n",
    "        kalman.predict()\n",
    "        predicted_bbox = tuple(map(int, kalman.statePost[:2, 0]))\n",
    "        cv2.rectangle(frame, (predicted_bbox[0] - bbox[2] // 2, predicted_bbox[1] - bbox[3] // 2),\n",
    "                      (predicted_bbox[0] + bbox[2] //2 , predicted_bbox[1] + bbox[3] // 2),\n",
    "                      (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Kalman Filter Tracking\", frame)\n",
    "        \n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def SIFT(path):\n",
    "    limited = (input(\"Set max limitation ? (y/n)\") == 'y')\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    MAX_KEYPOINTS = 100\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        if (len(keypoints) > MAX_KEYPOINTS) & limited:\n",
    "            keypoints = sorted(keypoints, key= lambda x: -x.response)[:MAX_KEYPOINTS]\n",
    "        \n",
    "        \n",
    "        frame = cv2.drawKeypoints(frame, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        \n",
    "        cv2.imshow(\"SIFT\", frame)\n",
    "        \n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def ORB(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        keypoints = orb.detect(gray, None)\n",
    "        frame = cv2.drawKeypoints(frame, keypoints, None, color=(0, 255, 0), flags=0)\n",
    "        \n",
    "        cv2.imshow(\"ORB\", frame)\n",
    "        \n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "n = input('''Choose tracking algo \\n\n",
    "          1. Mean-Shift\\n\n",
    "          2. Kalman Filter\\n\n",
    "          3. SIFT\\n\n",
    "          4. ORB\\n''')\n",
    "\n",
    "if n == '1':\n",
    "    MeanShift(video_path)\n",
    "elif n=='2':\n",
    "    Kalman(video_path)\n",
    "elif n=='3':\n",
    "    SIFT(video_path)\n",
    "elif n=='4':\n",
    "    ORB(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
